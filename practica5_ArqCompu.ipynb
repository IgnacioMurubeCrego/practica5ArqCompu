{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPbSe+3X2sY+GebumAUdAcZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IgnacioMurubeCrego/practica5ArqCompu/blob/main/practica5_ArqCompu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4Ik5PfN7NpK",
        "outputId": "c1d66a36-c7d2-4ff3-c82e-df2e758f766b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKtYgStn8WX_",
        "outputId": "87359cf2-5f6e-426d-b8fa-ac82874df37a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-f5uontjk\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-f5uontjk\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 28f872a2f99a1b201bcd0db14fdbc5a496b9bfd7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvcc4jupyter\n",
            "  Building wheel for nvcc4jupyter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvcc4jupyter: filename=nvcc4jupyter-1.2.1-py3-none-any.whl size=10742 sha256=fdb30b442a03a2b978d94f242f4f3839c3b517111d4c5bcc31496f40b5aacbba\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lch8r_k8/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built nvcc4jupyter\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0zRQwV19LpR",
        "outputId": "6c4ea33f-38ea-4b31-8372-e6f9e06ad06f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpodbxn7zu\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void hello(){\n",
        "    printf(\"Hello World from block: %u, thread: %u\\n\", blockIdx.x, threadIdx.x);\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    hello<<<2, 3>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAdlAQYf9qLh",
        "outputId": "d1a064e2-2282-4069-9718-4c35ac78f07d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World from block: 0, thread: 0\n",
            "Hello World from block: 0, thread: 1\n",
            "Hello World from block: 0, thread: 2\n",
            "Hello World from block: 1, thread: 0\n",
            "Hello World from block: 1, thread: 1\n",
            "Hello World from block: 1, thread: 2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wEgXVxh2EELn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejemplo B :  duplicar un valor con CUDA\n"
      ],
      "metadata": {
        "id": "eVrZZDdhCJOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// DEFINICIÓN KERNEL CUDA\n",
        "\n",
        "__global__ void duplicarValor(int *valor_device)\n",
        "\n",
        "{\n",
        "  printf(\"Block [2%u], Thread [2%u]: valor_device=%d\\n\", blockIdx.x, threadIdx.x, *valor_device);\n",
        "  *valor_device *= 2;\n",
        "}\n",
        "\n",
        "// FUNCIÓN DEL HOST\n",
        "\n",
        "int main()\n",
        "{\n",
        "\n",
        "  // 1 - INICIALIZAR DATOS DEL HOST\n",
        "\n",
        "  int valor_host = 5;\n",
        "\n",
        "  // valor inicial en el host\n",
        "\n",
        "  // 2 - DECLARAR Y ASIGNAR MEMORIA PARA EL DEVICE\n",
        "\n",
        "  int *valor_device; // puntero al device\n",
        "\n",
        "  cudaMalloc((void **)&valor_device, sizeof(int)); // asignar memoria para el device\n",
        "\n",
        "  // 3 - TRANSFERIR DATOS DEL HOST AL DEVICE\n",
        "\n",
        "  cudaMemcpy(valor_device, &valor_host, sizeof(int), cudaMemcpyHostToDevice); // transferir el valor del host al device\n",
        "\n",
        "  // 4 - EJECUTAR EN UNO O MÁS KERNELS\n",
        "\n",
        "  duplicarValor<<<1, 2>>>(valor_device); // lanzar el kernel\n",
        "\n",
        "  cudaDeviceSynchronize(); // espera hasta que el kernel termine\n",
        "\n",
        "  // 5 - TRANSFERIR DATOS DEL DEVICE AL HOST\n",
        "\n",
        "  cudaMemcpy(&valor_host, valor_device, sizeof(int), cudaMemcpyDeviceToHost); // transferir el valor del device al host\n",
        "\n",
        "  // 6 - LIBERAR RECURSOS\n",
        "\n",
        "  cudaFree(valor_device); // liberar memoria del device\n",
        "\n",
        "  // MOSTRAR RESULTADO\n",
        "\n",
        "  std::cout << \"Resultado: \" << valor_host << std::endl;\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Uz1xNMmCH5v",
        "outputId": "44e7521f-26e8-4d65-fef4-0a2a679d6f2b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Block [20], Thread [20]: valor_device=5\n",
            "Block [20], Thread [21]: valor_device=5\n",
            "Resultado: 10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejemplo C : suma de vectores con CUDA\n"
      ],
      "metadata": {
        "id": "jB9IAicrEG1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#define T_VEC 100\n",
        "\n",
        "//DEFINICIÓN KERNEL CUDA\n",
        "\n",
        "__global__ void sumaVectores(int* v1_device, int* v2_device, int*suma_device) {\n",
        "  printf(\"Índice de hilo dentro del bloque: %d\\n\", threadIdx.x);\n",
        "  printf(\"Índice del bloque: %d\\n\", blockIdx.x);\n",
        "  printf(\"Tamaño del bloque (número de hilos): %d\\n\", blockDim.x);\n",
        "  for (int i = 0; i < T_VEC; i++) {\n",
        "    suma_device[i] = v1_device[i] + v2_device[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "//FUNCIÓN DEL HOST\n",
        "\n",
        "int main() {\n",
        "\n",
        "  //1 - INICIALIZAR DATOS DEL HOST\n",
        "\n",
        "  int v1_host[T_VEC], v2_host[T_VEC], suma_host[T_VEC];\n",
        "  for (int i = 0; i < T_VEC; i++) {\n",
        "    v1_host[i] = 1;\n",
        "    v2_host[i] = 2;\n",
        "  }\n",
        "\n",
        "  //2 - DECLARAR Y ASIGNAR MEMORIA PARA EL DEVICE\n",
        "\n",
        "  int *v1_device, *v2_device, *suma_device; //punteros al device\n",
        "  cudaMalloc((void**)&v1_device, sizeof(int) * T_VEC); //asignar memoria para el device\n",
        "  cudaMalloc((void**)&v2_device, sizeof(int) * T_VEC);\n",
        "  cudaMalloc((void**)&suma_device, sizeof(int) * T_VEC);\n",
        "\n",
        "  //3 - TRANSFERIR DATOS DEL HOST AL DEVICE\n",
        "\n",
        "  cudaMemcpy(v1_device, v1_host, sizeof(int) * T_VEC,cudaMemcpyHostToDevice); //transferir el valor del host al device\n",
        "  cudaMemcpy(v2_device, v2_host, sizeof(int) * T_VEC,cudaMemcpyHostToDevice);\n",
        "  //cudaMemcpy(suma_device, suma_host, sizeof(int) * T_VEC,cudaMemcpyHostToDevice); //Inutil\n",
        "\n",
        "  //4 - EJECUTAR EN UNO O MÁS KERNELS\n",
        "\n",
        "  sumaVectores<<<1, 1>>>(v1_device, v2_device, suma_device);\n",
        "  //lanzar el kernel\n",
        "  cudaDeviceSynchronize(); //espera hasta que el kernel termine\n",
        "\n",
        "  //5 - TRANSFERIR DATOS DEL DEVICE AL HOST\n",
        "\n",
        "  cudaMemcpy(suma_host, suma_device, sizeof(int) * T_VEC,\n",
        "  cudaMemcpyDeviceToHost); //transferir el valor del device al host\n",
        "\n",
        "  //6 - LIBERAR RECURSOS\n",
        "  cudaFree(v1_device); //liberar memoria del device\n",
        "  cudaFree(v2_device);\n",
        "  cudaFree(suma_device);\n",
        "\n",
        "  //MOSTRAR RESULTADO\n",
        "  for (int i = 0; i < T_VEC; i++) {\n",
        "    std::cout << suma_host[i] << \" \";\n",
        "  }\n",
        "  std::cout << \"\\n\";\n",
        " return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgy32yb-ENMm",
        "outputId": "5d22cf5d-1a13-40c2-a9d3-7f1e239a905d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Índice de hilo dentro del bloque: 0\n",
            "Índice del bloque: 0\n",
            "Tamaño del bloque (número de hilos): 1\n",
            "3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ejercicio 1 (4 puntos)\n",
        "Modificar el ejemplo de suma de vectores con CUDA para que se ejecute en un bloque de\n",
        "25 hilos, dónde cada uno se encargue de sumar una parte de los vectores."
      ],
      "metadata": {
        "id": "qXT_T5BrGqLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#define T_VEC 100\n",
        "\n",
        "//DEFINICIÓN KERNEL CUDA\n",
        "\n",
        "__global__ void sumaVectores(int* v1_device, int* v2_device, int*suma_device) {\n",
        "  // printf(\"Índice de hilo dentro del bloque: %d\\n\", threadIdx.x);\n",
        "  // printf(\"Índice del bloque: %d\\n\", blockIdx.x);\n",
        "  // printf(\"Tamaño del bloque (número de hilos): %d\\n\", blockDim.x);\n",
        "  int threadInBlockIndex = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "  // Cada hilo suma un cuarto del vector\n",
        "    for (int i = threadInBlockIndex; i < T_VEC; i += blockDim.x * gridDim.x) {\n",
        "        suma_device[i] = v1_device[i] + v2_device[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "//FUNCIÓN DEL HOST\n",
        "\n",
        "int main() {\n",
        "\n",
        "  //1 - INICIALIZAR DATOS DEL HOST\n",
        "\n",
        "  int v1_host[T_VEC], v2_host[T_VEC], suma_host[T_VEC];\n",
        "  for (int i = 0; i < T_VEC; i++) {\n",
        "    v1_host[i] = 1;\n",
        "    v2_host[i] = 2;\n",
        "  }\n",
        "\n",
        "  //2 - DECLARAR Y ASIGNAR MEMORIA PARA EL DEVICE\n",
        "\n",
        "  int *v1_device, *v2_device, *suma_device; //punteros al device\n",
        "  cudaMalloc((void**)&v1_device, sizeof(int) * T_VEC); //asignar memoria para el device\n",
        "  cudaMalloc((void**)&v2_device, sizeof(int) * T_VEC);\n",
        "  cudaMalloc((void**)&suma_device, sizeof(int) * T_VEC);\n",
        "\n",
        "  //3 - TRANSFERIR DATOS DEL HOST AL DEVICE\n",
        "\n",
        "  cudaMemcpy(v1_device, v1_host, sizeof(int) * T_VEC,cudaMemcpyHostToDevice); //transferir el valor del host al device\n",
        "  cudaMemcpy(v2_device, v2_host, sizeof(int) * T_VEC,cudaMemcpyHostToDevice);\n",
        "  //cudaMemcpy(suma_device, suma_host, sizeof(int) * T_VEC,cudaMemcpyHostToDevice); //Inutil\n",
        "\n",
        "  //4 - EJECUTAR EN UNO O MÁS KERNELS\n",
        "\n",
        "  sumaVectores<<<1, 25>>>(v1_device, v2_device, suma_device);\n",
        "  //lanzar el kernel\n",
        "  cudaDeviceSynchronize(); //espera hasta que el kernel termine\n",
        "\n",
        "  //5 - TRANSFERIR DATOS DEL DEVICE AL HOST\n",
        "\n",
        "  cudaMemcpy(suma_host, suma_device, sizeof(int) * T_VEC,\n",
        "  cudaMemcpyDeviceToHost); //transferir el valor del device al host\n",
        "\n",
        "  //6 - LIBERAR RECURSOS\n",
        "  cudaFree(v1_device); //liberar memoria del device\n",
        "  cudaFree(v2_device);\n",
        "  cudaFree(suma_device);\n",
        "\n",
        "  //MOSTRAR RESULTADO\n",
        "  for (int i = 0; i < T_VEC; i++) {\n",
        "    std::cout << suma_host[i] << \" \";\n",
        "  }\n",
        "  std::cout << \"\\n\";\n",
        " return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a8a1977-7929-4bfe-ec10-2cbfbb49ffd8",
        "id": "dDhRmBCMGz5q"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 \n",
            "\n"
          ]
        }
      ]
    }
  ]
}